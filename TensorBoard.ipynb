{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard is a monitoring tools for training different models. It captures values during training so user can monitor the training process and figure out potential problem of a structure or training strategy.\n",
    "To visualise the tensorboard in jupyter notebook, we can strip the graph structure from the graph and display it in a HTML frame:(code copied from stackOverFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot within jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To show the tensorBoard\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create variable\n",
    "var3=tf.get_variable('Var3',shape=(1,1),dtype=tf.float64)\n",
    "\n",
    "#The variable will be created with the value used as its default value as it is initialised\n",
    "init = tf.Variable(451, tf.int16)\n",
    "const1=tf.constant(1,dtype=tf.float64)\n",
    "\n",
    "#Operations\n",
    "add1=var3+const1\n",
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a tensorboard, we will need to create a directory to store the logs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard CMD:tensorboard --logdir=C:/Users/kin.poon/Desktop/tf_logs20180718-151516/\n"
     ]
    }
   ],
   "source": [
    "#Opening new directory\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "logdir = 'C:/Users/kin.poon/Desktop/tf_logs' + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "os.mkdir(logdir)\n",
    "print('TensorBoard CMD:tensorboard --logdir='+logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the model is defined, we can define a summary object, in which we can record different variables in the graph. This summary objects need to be executed in the session together with the calculations to take the snapshots. There are different type of summary we can get. These summaries can help tracking the changes of variables so the user can observe the changes and debug the structure/procedure accordingly. For example, being able to observe the activation values will help getting insight on whether the information is passing through the network efficiently. The practitioner may then adjust the initiallisation, apply batch normalisation or re-design the structure to improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#-----\n",
    "#Cost and weights defined\n",
    "#-----\n",
    "\n",
    "tf.summary.scalar('Cost',cost) #Recording scalar 'Cost'.\n",
    "tf.summary.histogram('Weights',encoded) #Recording tensor 'Weights' and plot it as histogram.\n",
    "merged=tf.summary.merge_all()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the logs of different variables, we can merge all the summary into a single summary object for collective execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----\n",
    "#Session defined\n",
    "#-----\n",
    "\n",
    "#Define the writer with the graph, which contains the summaries and merged summary\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "\n",
    "# Training epochs\n",
    "for e in range(epochs):\n",
    "    for ii in range(num_examples//batch_size):\n",
    "        #Running the variable merged in the session to collect the merged summary \n",
    "        summary, batch_cost, _ = sess.run([merged,cost, opt], feed_dict={inputs_: imgs, targets_: imgs})\n",
    "        print(\"Running epochs {}, batch {}\".format(e+1,ii+1))\n",
    "        #Writing the summary down to the writer, which is the returned result of the collected summary.\n",
    "        writer.add_summary(summary, ii)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the summary, we will need to create a summary writer to write down the log for tensorboard to display."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings is a common technique used for NLP. It allows pratitioners to embedding data objects into a latent space which retain only significant features of the data(if the embedding is successful). Being able to visualise embeddings is important to determine whether the embedding training is successful or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "# ----------------- Logging the embeded tensor ---------------------------#\n",
    "# Create randomly initialized embedding weights which will be trained.\n",
    "N = 2000 # Number of items (vocab size).\n",
    "D = 200 # Dimensionality of the embedding.\n",
    "embedding_var = tf.Variable(tf.random_normal([N,D]), name='word_embedding')\n",
    "# ------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#----------------- Configuring the projector --------------------------------------#\n",
    "# Format: tensorflow/contrib/tensorboard/plugins/projector/projector_config.proto\n",
    "# Create the config object for the projector\n",
    "config = projector.ProjectorConfig()\n",
    "\n",
    "# You can add multiple embeddings. Here we add only one.\n",
    "\n",
    "# Add an embedding object in the config\n",
    "embedding = config.embeddings.add()\n",
    "# Linking the embedding object\n",
    "embedding.tensor_name = embedding_var.name\n",
    "# Link this tensor to its metadata file (e.g. labels).\n",
    "embedding.metadata_path = os.path.join('C:/Users/kin.poon/Desktop/tf_meta_test/', 'metaData.tsv')\n",
    "#----------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#----------------- For adding image thumbnails ------------------------------------#\n",
    "'''\n",
    "embedding.sprite.image_path = PATH_TO_SPRITE_IMAGE\n",
    "# Specify the width and height of a single thumbnail.\n",
    "embedding.sprite.single_image_dim.extend([w, h])\n",
    "'''\n",
    "#----------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#----------------- Writing the embeddings down ------------------------------------#\n",
    "# Use the same LOG_DIR where you stored your checkpoint.\n",
    "summary_writer = tf.summary.FileWriter(logdir)\n",
    "\n",
    "# The next line writes a projector_config.pbtxt in the LOG_DIR. TensorBoard will\n",
    "# read this file during startup.\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "#----------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver([embedding_var])\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.save(sess, os.path.join(logdir, 'embeddings.ckpt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
